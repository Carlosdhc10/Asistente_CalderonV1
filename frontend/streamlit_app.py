import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import os

# Configuraci√≥n de la app
st.set_page_config(page_title="Asistente Sequ√≠a Calder√≥n", page_icon="üíß", layout="wide")
st.title("üíß Asistente de An√°lisis de Sequ√≠as - Calder√≥n")

DATA_PATH = os.path.join("data", "C20-Calder√≥n_Precipitaci√≥n-Diario.csv")

@st.cache_data(show_spinner=False)
def cargar_datos():
    try:
        df = pd.read_csv(DATA_PATH, parse_dates=["fecha"])
        return df
    except Exception as e:
        st.error(f"‚ùå No se pudo cargar el archivo CSV: {e}")
        return pd.DataFrame()

def interpretar_grafica(prompt: str, modelo: str) -> str:
    try:
        with st.spinner("Consultando al asistente IA..."):
            response = requests.post(
                "http://localhost:8000/chatbot",
                json={"pregunta": prompt, "modelo": modelo.lower()},
                timeout=20
            )
        if response.status_code == 200:
            return response.json().get("respuesta", "Sin respuesta.")
        else:
            return f"Error: {response.status_code}"
    except Exception as e:
        return f"Error al conectar con el backend: {e}"

# Inicializar estados de sesi√≥n para interpretaciones
if "interpretaciones" not in st.session_state:
    st.session_state.interpretaciones = {
        "registros": "",
        "tendencia": "",
        "dispersion": "",
        "histograma": ""
    }

tab1, tab2, tab3, tab4 = st.tabs(["ü§ñ Asistente Conversacional", "üì° An√°lisis de Datos", "‚¨ÜÔ∏è Subir tus propios datos", "üìÑ Generar Reporte y Enviar Correo"])

with tab1:
    st.subheader("Haz preguntas sobre la sequ√≠a o el suministro de agua ‚ùì")

    if "historial" not in st.session_state:
        st.session_state.historial = []

    if "input_pregunta" not in st.session_state:
        st.session_state.input_pregunta = ""

    if "modelo_seleccionado" not in st.session_state:
        st.session_state.modelo_seleccionado = "OpenAI"

    modelo_opciones = ["OpenAI", "HuggingFace"]
    modelo_elegido = st.selectbox(
        "Selecciona el modelo de lenguaje:", 
        modelo_opciones, 
        index=modelo_opciones.index(st.session_state.modelo_seleccionado)
    )
    st.session_state.modelo_seleccionado = modelo_elegido

    def enviar_pregunta():
        pregunta = st.session_state.input_pregunta.strip()
        if not pregunta:
            st.warning("Por favor, ingresa una pregunta v√°lida.")
            return
        try:
            with st.spinner("Consultando al asistente..."):
                response = requests.post(
                    "http://localhost:8000/chatbot",
                    json={"pregunta": pregunta, "modelo": st.session_state.modelo_seleccionado.lower()},
                    timeout=15
                )
            if response.status_code == 200:
                respuesta = response.json().get("respuesta", "Sin respuesta.")
                st.session_state.historial.append({
                    "pregunta": pregunta,
                    "respuesta": respuesta,
                    "modelo": st.session_state.modelo_seleccionado
                })
                st.session_state.input_pregunta = ""
            else:
                st.error(f"Error al contactar con el backend: {response.status_code}")
        except requests.exceptions.Timeout:
            st.error("El servidor no respondi√≥ a tiempo. Intenta de nuevo m√°s tarde.")
        except Exception as e:
            st.error(f"No se pudo conectar con el backend: {e}")

    st.text_input("Tu pregunta:", key="input_pregunta", on_change=enviar_pregunta)

    for turno in st.session_state.historial:
        st.markdown(f"**Modelo ({turno['modelo']}):**")
        st.markdown(f"**T√∫:** {turno['pregunta']}")
        st.markdown(f"**Asistente:** {turno['respuesta']}")
        st.markdown("---")

with tab2:
    st.subheader("üíß Explora los datos hist√≥ricos del suministro de agua")

    df = cargar_datos()
    if df.empty:
        st.stop()

    if not {"fecha", "valor"}.issubset(df.columns):
        st.error("El archivo debe contener las columnas 'fecha' y 'valor'.")
        st.stop()

    df["a√±o"] = df["fecha"].dt.year

    # Funci√≥n local para solicitar interpretaci√≥n y actualizar estado
    def solicitar_interpretacion(clave, prompt):
        resp = interpretar_grafica(prompt, st.session_state.modelo_seleccionado)
        st.session_state.interpretaciones[clave] = resp

    # N√∫mero de registros por a√±o
    st.markdown("üìä ### N√∫mero de registros por a√±o")
    st.bar_chart(df.groupby("a√±o").size())
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Interpretar con IA - Registros por a√±o"):
            prompt = (
                "Analiza el gr√°fico de barras titulado N√∫mero de registros por a√±o. Describe la tendencia "
                "del N√∫mero de registros desde 2020 hasta 2025. Espec√≠ficamente, identifica el a√±o con la menor "
                "cantidad de registros, los a√±os con la mayor cantidad consistente de registros y explica el cambio "
                "aparente observado en el a√±o 2025, teniendo en cuenta que los datos para 2025 podr√≠an ser parciales. "
                "Hipotetiza qu√© podr√≠a causar este patr√≥n en el n√∫mero de registros a lo largo de estos a√±os."
            )
            solicitar_interpretacion("registros", prompt)
    with col2:
        if st.button("Limpiar interpretaci√≥n - Registros"):
            st.session_state.interpretaciones["registros"] = ""

    if st.session_state.interpretaciones["registros"]:
        st.info(st.session_state.interpretaciones["registros"])

    # Tendencia temporal
    st.markdown("üìä ### Variaci√≥n de disponibilidad de agua a lo largo del tiempo")
    st.plotly_chart(px.line(df, x="fecha", y="valor", title="Tendencia de disponibilidad de agua"), use_container_width=True)
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Interpretar con IA - Tendencia temporal"):
            prompt = "Interpreta la tendencia de la disponibilidad de agua en Calder√≥n seg√∫n la gr√°fica de l√≠nea generada."
            solicitar_interpretacion("tendencia", prompt)
    with col2:
        if st.button("Limpiar interpretaci√≥n - Tendencia"):
            st.session_state.interpretaciones["tendencia"] = ""

    if st.session_state.interpretaciones["tendencia"]:
        st.info(st.session_state.interpretaciones["tendencia"])

    # Dispersi√≥n
    st.markdown("üìä ### Dispersi√≥n de valores en el tiempo")
    st.plotly_chart(px.scatter(df, x="fecha", y="valor", title="Dispersi√≥n del indicador 'valor'"), use_container_width=True)
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Interpretar con IA - Dispersi√≥n temporal"):
            prompt = "Describe la dispersi√≥n de los valores de disponibilidad de agua en el tiempo en Calder√≥n."
            solicitar_interpretacion("dispersion", prompt)
    with col2:
        if st.button("Limpiar interpretaci√≥n - Dispersi√≥n"):
            st.session_state.interpretaciones["dispersion"] = ""

    if st.session_state.interpretaciones["dispersion"]:
        st.info(st.session_state.interpretaciones["dispersion"])

    # Histograma
    st.markdown("üìä ### Distribuci√≥n del indicador 'valor' (Histograma)")
    st.plotly_chart(px.histogram(df, x="valor", nbins=30, title="Histograma de valores"), use_container_width=True)
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Interpretar con IA - Histograma"):
            prompt = "Analiza el histograma de distribuci√≥n de valores de disponibilidad de agua en Calder√≥n."
            solicitar_interpretacion("histograma", prompt)
    with col2:
        if st.button("Limpiar interpretaci√≥n - Histograma"):
            st.session_state.interpretaciones["histograma"] = ""

    if st.session_state.interpretaciones["histograma"]:
        st.info(st.session_state.interpretaciones["histograma"])

    # --- Resumen ---
    total_dias = df.shape[0]
    dias_sin_agua = df[df["valor"] == 0].shape[0]
    porcentaje_sin_agua = (dias_sin_agua / total_dias) * 100 if total_dias > 0 else 0

    fiabilidad = None
    if {"completo_mediciones", "completo_umbral"}.issubset(df.columns):
        fiabilidad = (df["completo_mediciones"] >= df["completo_umbral"]).sum() / total_dias * 100

    resumen = {
        "Total de d√≠as registrados": total_dias,
        "D√≠as sin agua (valor = 0)": dias_sin_agua,
        "Porcentaje sin disponibilidad (%)": round(porcentaje_sin_agua, 2),
        "Fiabilidad (%)": round(fiabilidad, 2) if fiabilidad is not None else "No disponible"
    }
    st.markdown("### Resumen de indicadores")
    st.json(resumen)

with tab3:
    st.subheader("3Ô∏è‚É£ An√°lisis de archivo personalizado")

    archivo_cargado = st.file_uploader("Sube tu archivo CSV", type=["csv"])
    
    if archivo_cargado is not None:
        df_personalizado = pd.read_csv(archivo_cargado)
        
        # Mostrar datos cargados
        st.success("‚úÖ Archivo cargado correctamente.")
        st.dataframe(df_personalizado.head())

        # Mostrar gr√°fica
        if "fecha" in df_personalizado.columns and "valor" in df_personalizado.columns:
            df_personalizado["fecha"] = pd.to_datetime(df_personalizado["fecha"], errors="coerce")
            st.line_chart(df_personalizado.set_index("fecha")["valor"])

            # Construir prompt de an√°lisis
            prompt_analisis = (
                f"Aqu√≠ tienes datos de disponibilidad de agua para Calder√≥n:\n{df_personalizado.head(30).to_string(index=False)}\n\n"
                "Por favor, proporciona un an√°lisis t√©cnico de la situaci√≥n de sequ√≠a bas√°ndote en los datos proporcionados. "
                "Incluye observaciones, posibles causas y recomendaciones."
            )

            # Mostrar bot√≥n para interpretaci√≥n con modelo seleccionado
            if st.button("üß† Interpretar con IA"):
                modelo = st.session_state.get("modelo_seleccionado", "openai").lower()
                st.info(f"Generando an√°lisis autom√°tico con el modelo: {modelo}...")

                try:
                    analisis_automatico = interpretar_grafica(prompt_analisis, modelo=modelo)
                    st.markdown("### üîç An√°lisis generado por IA")
                    st.write(analisis_automatico)
                except Exception as e:
                    st.error(f"‚ùå Error al generar el an√°lisis con IA: {e}")
        else:
            st.warning("El archivo debe tener las columnas 'fecha' y 'valor'.")

with tab4:
    st.subheader("4Ô∏è‚É£ Generar Reporte PDF y Enviar por Correo")

    if "reporte_generado" not in st.session_state:
        st.session_state.reporte_generado = False

    if st.button("üìÑ Generar Reporte PDF"):
        with st.spinner("üöÄ Generando reporte... por favor espera"):
            try:
                respuesta = requests.get("http://localhost:8000/reporte")
                if respuesta.status_code == 200:
                    with open("reporte_sequia.pdf", "wb") as f:
                        f.write(respuesta.content)
                    st.success("‚úÖ Reporte generado exitosamente.")
                    st.session_state.reporte_generado = True
                else:
                    st.error(f"‚ùå Error al generar el reporte: {respuesta.text}")
            except Exception as e:
                st.error(f"‚ùå No se pudo conectar con el backend: {e}")

    if st.session_state.reporte_generado:
        with open("reporte_sequia.pdf", "rb") as pdf_file:
            st.download_button(
                label="üì• Descargar Reporte",
                data=pdf_file,
                file_name="reporte_sequia.pdf",
                mime="application/pdf"
            )

    st.markdown("---")

    st.markdown("### ‚úâÔ∏è Enviar Reporte por Correo")
    email_destinatario = st.text_input("Ingrese correo del destinatario")

    if st.button("üì¨ Enviar Correo"):
        if not email_destinatario:
            st.warning("‚ö†Ô∏è Debes ingresar un correo v√°lido.")
        else:
            with st.spinner("üöÄ Enviando correo..."):
                try:
                    payload = {"destinatario": email_destinatario}
                    respuesta = requests.post("http://localhost:8000/reporte/enviar", json=payload)
                    if respuesta.status_code == 200:
                        st.success("‚úÖ Correo enviado exitosamente.")
                    else:
                        st.error(f"‚ùå Error al enviar correo: {respuesta.text}")
                except Exception as e:
                    st.error(f"‚ùå Error de conexi√≥n con backend: {e}")

